{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Localización y clasificación de objetos en video con YOLO**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Instalar onnx.**\n",
    "Herramienta para modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Librerías.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En particular usaremos extensivamente el paquete y funciones ```cv2.dnn``` que permiten implementar yolo de una manera muy fácil y sencilla en cualquier aplicación escrita en Python donde se trabaje con imágenes. \n",
    "\n",
    "Primero necesitamos cargar los nombres de las clases en las que se ha entrenado la red. Ten en cuenta que la red que utilicemos solo podrá reconocer las clases en las que se ha formado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLabels(path):\n",
    "    try:\n",
    "        labels = open(path).read().strip().split(\"\\n\")\n",
    "        return labels\n",
    "    except:\n",
    "        print(\"Error: Could not read file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"./yolo-coco/coco.names\"\n",
    "LABELS = readLabels(labelsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'bicycle', 'car', 'motorbike', 'aeroplane']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora generaremos un color para cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar semilla de números pseudo-aleatorios\n",
    "np.random.seed(42)\n",
    "# Color para cada clase\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos el color de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 220, 225],\n",
       "       [ 95, 179,  61],\n",
       "       [234, 203,  92],\n",
       "       [  3,  98, 243],\n",
       "       [ 14, 149, 245]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLORS[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para hacer una imagen cuadrada\n",
    "def format_yolov5(frame):\n",
    "    row, col, _ = frame.shape\n",
    "    _max = max(col, row)\n",
    "    result = np.zeros((_max, _max, 3), np.uint8)\n",
    "    result[0:row, 0:col] = frame\n",
    "    return result\n",
    "\n",
    "# Cambiamos la imagen a un cuadrado de 640x640 píxeles y hacemos un forward\n",
    "def forward(net, input_image):\n",
    "    blob = cv2.dnn.blobFromImage(input_image, 1 / 255.0, (640, 640), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward()\n",
    "    end = time.time()\n",
    "    return layerOutputs, start, end\n",
    "\n",
    "# Seleccionador de cuadros delimitadores\n",
    "def bounding_boxes(layerOutputs, input_image):\n",
    "    class_ids, confidences, boxes = [], [], []\n",
    "    output_data = layerOutputs[0]\n",
    "    \n",
    "    image_width, image_height, _ = input_image.shape\n",
    "    x_factor = image_width / 640\n",
    "    y_factor =  image_height / 640\n",
    "    \n",
    "    # Hacemos un bucle para cada una de las detecciones\n",
    "    for r in range(len(output_data)):\n",
    "        row = output_data[r]\n",
    "        confidence = row[4]\n",
    "\n",
    "        if confidence >= .4:\n",
    "\n",
    "            classes_scores = row[5:] \n",
    "            _, _, _, max_indx = cv2.minMaxLoc(classes_scores)\n",
    "            class_id = max_indx[1]\n",
    "            \n",
    "            if (classes_scores[class_id] > .25):\n",
    "                \"\"\"Escalar las coordenadas del cuadro delimitador hacia atrás en relación con el\n",
    "                tamaño de la imagen, teniendo en cuenta que YOLO en realidad\n",
    "                devuelve las coordenadas del centro (x, y) del límite\n",
    "                cuadro seguido del ancho y alto de los cuadros.\"\"\"\n",
    "                \n",
    "                confidences.append(confidence)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item() \n",
    "                \n",
    "                left = int((x - 0.5 * w) * x_factor)\n",
    "                top = int((y - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                \n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "                \n",
    "    return class_ids, confidences, boxes\n",
    "\n",
    "# Dibujar cuadros\n",
    "def draw_boxes(boxes, confidences, class_ids, image):\n",
    "    # aplicar supresión no máxima para suprimir cuadros delimitadores débiles y superpuestos\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.2)\n",
    "    # asegúrese de que exista al menos una detección\n",
    "    if len(idxs) > 0:\n",
    "        # bucle sobre los índices que estamos manteniendo\n",
    "        for i in idxs.flatten():\n",
    "            # extraer las coordenadas del cuadro delimitador\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # dibuje un rectángulo de cuadro delimitador y una etiqueta en la imagen\n",
    "            color = [int(c) for c in COLORS[class_ids[i]]]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            text = \"{}: {:.4f}\".format(LABELS[class_ids[i]], confidences[i])\n",
    "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos nuestro modelo de Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading YOLO from disk...\n"
     ]
    }
   ],
   "source": [
    "modelPath = \"./yolo-coco/yolov5s.onnx\"\n",
    "\n",
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNet(modelPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos el video que queremos analizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./videos/test/soccer.mp4')\n",
    "writer  = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinamos el número total de frames en el video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "frames = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "\t\telse cv2.CAP_PROP_FRAME_COUNT\n",
    "total = int(video.get(frames))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorremos los frames del video y analizamos frame por frame, guardamos las etiquetas y marcos de los objetos detectados en el mismo video, generando otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\t# Leer el siguiente frame\n",
    "\t(r, frame) = video.read()\n",
    "\t# Si el frame no fue leido, salimos del loop\n",
    "\tif not r:\n",
    "\t\tbreak\n",
    "\n",
    "\t# Construimos un blob desde el marco de entrada y luego realizamos un envío de este\n",
    "\t# hacía el detector de objetos (YOLO). Para construir los marcos de salida, y las probabilidades\n",
    "\t# Necesitamos cambiar el tamaño de la imagen a un cuadrado de 416x416 píxeles y hacer un pase hacia adelante a través de la red.\n",
    "\n",
    "\tinput_frame = format_yolov5(frame)\n",
    "\t\n",
    "\tlayerOutputs, start, end = forward(net, input_frame)\n",
    "\n",
    "\t# Inicializamos la lista de marcos de salida detectados, las clases y las probabilidades respectivamente\n",
    "\tclass_ids, confidences, boxes = bounding_boxes(layerOutputs, input_frame)\n",
    "\n",
    "\tdraw_boxes(boxes, confidences, class_ids, frame)\n",
    "\n",
    "\t# Si el video writer no está inicializado, inicializamos uno\n",
    "\tif writer is None:\n",
    "\t\t# Inicializamos nuestro video writer\n",
    "\t\tformat = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\t\twriter = cv2.VideoWriter(\"./videos/detection/video_soccer_detection.mp4\", format, 30, (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "\t# Guardamos el video con las etiquetas y los marcos de salida\n",
    "\twriter.write(frame)\n",
    "writer.release()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110fe3fb9777db4ce1f884af3cc527a40b2c98427ad17781c021ef692bd3d28d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
